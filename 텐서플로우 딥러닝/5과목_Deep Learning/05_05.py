# 신경망을 통한 AND OR 문제 (인공신경망 개요와 뉴런, 단층 퍼셉트론(1))
#
# 2장. 인공신경망(Artificial Neural Network)    
#
#   - 인공신경망
#     . 인간의 놀라운 인식력과 판단력은 단순한 기능을 가진 몇 개의 신경세포 조합에 의해 행해진다.
#        ==> 인간의 신경세포 조직을 인위로 만들 수 없을까?
# 
#   - 인공 신경망의 연구
#     . 1943년 매컬릭(McCulloch)과 피츠(Pitts): 인간의 뇌를 수많은 신경세포가 연결된 하나의 디지털 네트워크 모형으로 간주하고 
#       신경세포의 신호처리 과정을 모형화하여 단순 패턴분류 모형을 개발
#     . 헵(Hebb): 신경세포(뉴런) 사이의 연결강도(weight)를 조정하여 학습 규칙을 개발
#     . 로젠블럿(RTosenblatt, 1955): 퍼셉트론(Perceptron)이라는 인공세포 개발
#     . 비선형성의 한계점 발생 - XOR(Exclusive OR) 문제
#     . 폴 월보스(1974), 힌튼(Hinton, 1986): 역전파 알고리즘(Backpropagation)을 활용하여 비선형성을 극복한 
#       다계층 퍼셉트론으로 새로운 인공신경망 모형 등장
#    
#   - 인공 신경망
#     . 인간 뇌를 기반으로 한 추론 모델
#     . 인간 뇌의 추론 모델 - 뉴론(neuron)
#     . 뉴런은 기본적인 정보 처리 단위
#
#  - 인간 뇌의 특징
#    . 100억개의 뉴런과 각 뉴런을 연결하는 6조 개의 시냅스의 결합체
#    . 인간의 뇌는 현존하는 어떤 컴퓨터보다 빠르게 기능을 수행할 수 있음
#    . 인간의 뇌는 매우 복잡하고, 비선형적이며, 병렬적인 정보 처리 시스템으로 생각할 수 있음
#    . 정보는 신경망 전체에 동시에 저장되고 처리됨
#    . 적응성에 따라 '잘못된 답'으로 이끄는 뉴런들 사이의 연결은 약화되고 '올바른 답'으로 이끄는 연결은 강화됨 
#
#  - 인간의 뇌 모델링
#    . 생물학적인 뇌의 뉴런과 비슷하게 모델링 함 
#    . 인공신경망은 뉴런이라는 아주 단순하지만 내부적으로 매우 복잡하게 연결된 프로세스들로 이루어져 있음
#    . 뉴런은 가중치가 잇는 링크들로 연결되어 있음
#    . 각각의 뉴런은 연결을 통해 여러 입력 신호를 받지만 출력 신호는 오직 하나만 생성
#    . 인공 신경망 구조
#
#  - 인공 신경망의 학습
#    . 신경망은 가중치를 반복적으로 조정하여 학습
#    . 뉴런은 링크(link)로 연결되어 있고, 각 링크에는 그와 연관된 수치적인 가중치가 있음
#    . 가중치는 장기 기억을 위한 기본적인 수단으로 각 뉴런 입력 강도, 즉 중요도를 푷션
#
#  - 인공 신경망의 가중치 조정
#    . 신경망의 가중치를 초기화하고 훈련 예제들의 집합들의 집합에서 해당 가중치를 갱신
#    . 신경망의 구조를 먼저 선택하고, 어떤 학습 알고리즘을 사용할지 결정한 후 신경망을 훈련시킴
#
#  - 뉴런의 특징
#    . 입력 링크에서 여러 신호를 받아서 새로운 활성화 수준을 계산하고 출력 링크로 출력 신호를 보냄
#    . 입력 신호는 미가공 데이터 또는 다른 뉴런의 출력이 될 수 있음
#    . 출력 신호는 문제의 최종적인 해(Solution)가 되거나 다른 뉴런에 입력 될 수 있음
#
#  - 뉴런의 계산
#    . 뉴런은 전이함수, 즉 활성화 함수(Activation function)을 사용
#    . 활성화 함수를 이용한 출력 결정 순서
#      1. 뉴런은 입력 신호의 가중치 합을 계산하여 임계값과 비교
#      2. 가중치 합이 임계값보다 작으면 뉴런의 출력은 -1, 같거나 크면 +1을 추력함 
#    . 활성화 함수 
#          X = sigma(Xi*Wi)          Y = +1 if X>= 0 , -1 < 0               
#
#
#  - 뉴런의 출력 결정
#    . 활성화 함수를 부호함수를 사용하는 뉴런의 실제 출력
#
#  - 뉴런의 활성화 함수
#    . 계단 함수/부호 함수/시그모이드 함수/선형 함수
#
#  - 단일 뉴런의 학습(단층 퍼셉트론)
#    . 퍼셉트론은 선형 결합기와 하드 리미터로 구성
#    . 초평면(hyperplan)으로 n 차원 공간을 두 개의 결정 영역으로 나눔
#
#           x1 -----> W1
#                         -   w1x1
#                                     Sigma(Wi*Xi) | 0   ==> Y
#                         -   w2x2
#           x2 -----> W2             |   뉴런          |  
#
#
#    . 선형 분리 함수 :  sigma(Xi * Wi) - 0 = O
#      
#   - 단일 뉴런의 학습(단층 퍼셉트론)
#    . 입력이 2개일 때와 3개일 때의 퍼셉트론 도식화
#       -> X1W1 + W2W2 + 0 = O
#       -> X1W1 + X2W2 + X3W30 = O
#
#
#
